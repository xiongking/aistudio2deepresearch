import { GoogleGenAI, Type } from "@google/genai";
import { ResearchConfig, ResearchLog, Source, Settings } from "../types";

const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

export class DeepResearchService {
  private googleAI: GoogleGenAI | null = null;
  private settings: Settings | null = null;
  private cancelFlag: boolean = false;
  private searchCount: number = 0; // Track local search count

  constructor() {}

  private initAI(settings: Settings) {
    this.settings = settings;
    if (!settings.apiKey) {
      throw new Error("è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key");
    }

    if (settings.provider === 'google') {
      this.googleAI = new GoogleGenAI({ 
        apiKey: settings.apiKey,
      }, {
        // @ts-ignore
        baseUrl: settings.baseUrl || undefined 
      });
    } else {
      this.googleAI = null;
    }
  }

  cancel() {
    this.cancelFlag = true;
  }

  private checkCancelled() {
    if (this.cancelFlag) throw new Error("ç”¨æˆ·å–æ¶ˆäº†ç ”ç©¶ã€‚");
  }

  private async generateText(prompt: string, model: string, systemInstruction?: string, jsonMode?: boolean): Promise<{ text: string, usage?: number }> {
    if (!this.settings) throw new Error("è®¾ç½®æœªåˆå§‹åŒ–");

    // --- Google Provider ---
    if (this.settings.provider === 'google') {
      if (!this.googleAI) throw new Error("Google AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥");
      const config: any = {};
      if (jsonMode) {
         config.responseMimeType = 'application/json';
      }
      if (systemInstruction) {
         config.systemInstruction = systemInstruction;
      }
      
      const response = await this.googleAI.models.generateContent({
        model: model,
        contents: prompt,
        config: config
      });
      
      const usage = response.usageMetadata?.totalTokenCount || 0;
      return { text: response.text || "", usage };
    } 
    
    // --- OpenAI Compatible Provider ---
    else {
      const baseUrl = this.settings.baseUrl || "https://api.openai.com/v1";
      const url = `${baseUrl.replace(/\/$/, '')}/chat/completions`;
      
      const messages = [];
      if (systemInstruction) {
        messages.push({ role: "system", content: systemInstruction });
      }
      messages.push({ role: "user", content: prompt });

      const body: any = {
        model: model,
        messages: messages,
        temperature: 0.7
      };
      
      if (jsonMode) {
        body.response_format = { type: "json_object" };
      }

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${this.settings.apiKey}`
        },
        body: JSON.stringify(body)
      });

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`OpenAI æ¥å£é”™è¯¯ (${response.status}): ${err}`);
      }

      const data = await response.json();
      return { 
          text: data.choices?.[0]?.message?.content || "",
          usage: data.usage?.total_tokens || 0
      };
    }
  }

  /**
   * Tavily Search API
   */
  private async searchTavily(query: string, apiKey: string): Promise<{ summary: string; sources: Source[] }> {
    this.searchCount++;
    try {
      const response = await fetch("https://api.tavily.com/search", {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          api_key: apiKey,
          query: query,
          search_depth: "basic",
          include_answer: true,
          max_results: 5
        })
      });

      if (!response.ok) {
        console.warn("Tavily Search failed", await response.text());
        return { summary: "", sources: [] };
      }

      const data = await response.json();
      const summary = data.answer || data.results?.map((r: any) => r.content).join('\n\n') || "";
      const sources = data.results?.map((r: any) => ({
        title: r.title,
        uri: r.url
      })) || [];

      return { summary, sources };
    } catch (e) {
      console.error("Tavily error", e);
      return { summary: "", sources: [] };
    }
  }

  /**
   * Performs Search
   */
  private async search(query: string, model: string): Promise<{ summary: string; sources: Source[] }> {
    if (!this.settings) throw new Error("è®¾ç½®æœªåˆå§‹åŒ–");

    // 1. Tavily Search
    if (this.settings.provider !== 'google' && this.settings.tavilyApiKey) {
       return this.searchTavily(query, this.settings.tavilyApiKey);
    }

    // 2. Google Provider with Native Search
    if (this.settings.provider === 'google' && this.googleAI) {
      try {
        const response = await this.googleAI.models.generateContent({
          model: model,
          contents: `ç ”ç©¶ä»»åŠ¡: "${query}". æå–ç²¾ç¡®çš„äº‹å®ã€æ•°æ®å’Œæ—¥æœŸã€‚è¯·ç”¨ä¸­æ–‡æ€»ç»“å‘ç°ã€‚`,
          config: { tools: [{ googleSearch: {} }] }
        });

        const rawSources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
        const sources = rawSources
          .filter((c: any) => c.web?.uri && c.web?.title)
          .map((c: any) => ({ title: c.web.title, uri: c.web.uri }));

        return { summary: response.text || "", sources };
      } catch (e) {
        return { summary: "", sources: [] };
      }
    } 
    
    // 3. Fallback / No Search Tool
    else {
      const prompt = `
        ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰å³æ—¶äº’è”ç½‘çŸ¥è¯†çš„æœç´¢å¼•æ“ã€‚
        è¯·é’ˆå¯¹ä»¥ä¸‹æŸ¥è¯¢æä¾›è¯¦ç»†çš„ã€åŸºäºäº‹å®çš„æ‘˜è¦ï¼ŒåŒ…å«æ•°æ®ã€æ—¥æœŸå’Œå…³é”®å®ä½“ã€‚
        æŸ¥è¯¢: "${query}"
        
        æ–‡æœ«è¯·åˆ—å‡ºæ¨¡æ‹Ÿçš„æƒå¨æ¥æºã€‚
      `;
      try {
         const { text } = await this.generateText(prompt, model, "You are a helpful research assistant.");
         return { 
             summary: text, 
             sources: [{ title: "AI å†…éƒ¨çŸ¥è¯†åº“ (OpenAI/Fallback)", uri: "#ai-internal" }] 
         };
      } catch (e) {
          return { summary: "", sources: [] };
      }
    }
  }

  // --- Step 1: Generate Plan ---
  async generateResearchPlan(config: ResearchConfig, settings: Settings): Promise<{ title: string; chapters: string[], usage: number }> {
    this.cancelFlag = false;
    this.initAI(settings);
    const model = settings.model || (settings.provider === 'google' ? 'gemini-3-pro-preview' : 'gpt-4o');
    const currentDate = new Date().toLocaleDateString('zh-CN', { year: 'numeric', month: 'long', day: 'numeric' });
    const currentYear = new Date().getFullYear();
    
    // Slightly increased chapter count for "Deep" default
    const chapterCount = config.depth === 1 ? 4 : config.depth === 2 ? 6 : 10;
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶å¯¼å¸ˆã€‚å½“å‰æ—¶é—´æ˜¯ ${currentDate}ã€‚è¯·ä»¥JSONæ ¼å¼è¾“å‡ºã€‚`;
    const userPrompt = `
      ä¸»é¢˜: "${config.query}"
      ç›®æ ‡: ä¸ºä¸€ä»½æ·±åº¦ç ”ç©¶æŠ¥å‘Šåˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„ç›®å½•ï¼ˆç›®æ ‡å¤§çº¦ ${chapterCount} ä¸ªä¸»è¦ç« èŠ‚ï¼‰ã€‚
      
      è¦æ±‚:
      1. æ ‡é¢˜å¿…é¡»å…·æœ‰å­¦æœ¯æ€§ä¸”æè¿°æ€§å¼ºï¼Œå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚
      2. ç« èŠ‚å¿…é¡»æ¶µç›–å†å²èƒŒæ™¯ã€æŠ€æœ¯æœºåˆ¶ã€å¸‚åœºåˆ†æã€æŒ‘æˆ˜å’Œæœªæ¥å±•æœ›ç­‰ã€‚
      3. **ä¸¥ç¦åŒ…å«â€œä¼¦ç†è€ƒé‡â€ã€â€œé“å¾·é£é™©â€æˆ–ç±»ä¼¼çš„ç« èŠ‚**ã€‚è¯·ä¸“æ³¨äºæŠ€æœ¯ã€ç§‘å­¦ã€ç»æµæˆ–å†å²å±‚é¢çš„æ·±åº¦ã€‚
      4. é€»è¾‘æµç•…ï¼Œå±‚å±‚é€’è¿›ã€‚
      5. è¾“å‡ºå¿…é¡»å®Œå…¨ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
      6. **æ—¶æ•ˆæ€§**: è¿™æ˜¯ä¸€ä¸ª ${currentYear} å¹´çš„ç ”ç©¶ã€‚è¯·ç¡®ä¿ç« èŠ‚è®¾è®¡èƒ½å¼•å¯¼AIå»æŒ–æ˜ ${currentYear} æˆ– ${currentYear-1} å¹´çš„æœ€æ–°æ•°æ®ï¼Œè€Œä¸æ˜¯é™ˆæ—§çš„å†å²æ•°æ®ã€‚
      
      è¿”å› JSON: { "title": "æŠ¥å‘Šæ ‡é¢˜", "chapters": ["1. ç»ªè®º", "2. æ–‡çŒ®ç»¼è¿°...", ...] }
    `;

    try {
      const { text, usage } = await this.generateText(userPrompt, model, systemPrompt, true);
      const cleanText = text.replace(/```json\n|\n```/g, '');
      const json = JSON.parse(cleanText);
      
      if (!json.chapters || !Array.isArray(json.chapters)) {
          return { 
              title: json.title || config.query, 
              chapters: ["ç ”ç©¶èƒŒæ™¯", "æ ¸å¿ƒæŠ€æœ¯åˆ†æ", "å¸‚åœºç°çŠ¶", "æŒ‘æˆ˜ä¸æœºé‡", "ç»“è®ºä¸å±•æœ›"],
              usage: usage || 0
          };
      }
      return { ...json, usage: usage || 0 };
    } catch (e) {
      console.error("Outline failed", e);
      return { title: config.query, chapters: ["ç ”ç©¶èƒŒæ™¯", "æ ¸å¿ƒåˆ†æ", "ç»“è®º"], usage: 0 };
    }
  }

  // --- Step 2: Execute Research ---
  async *executeResearch(
    config: ResearchConfig, 
    settings: Settings, 
    title: string, 
    chapters: string[]
  ): AsyncGenerator<ResearchLog> {
    this.initAI(settings); 
    const model = settings.model || (settings.provider === 'google' ? 'gemini-3-pro-preview' : 'gpt-4o');
    
    const globalSources: Source[] = [];
    const uniqueSourceMap = new Map<string, number>(); // uri -> index (1-based)
    const reportSections: string[] = [];
    const chapterFindingsCache: string[] = [];
    let totalTokens = 0;
    this.searchCount = 0;

    // Yield initial info
    yield {
       id: crypto.randomUUID(),
       timestamp: Date.now(),
       type: 'info',
       message: 'å¤§çº²å·²ç¡®è®¤ï¼Œå¼€å§‹æ·±åº¦ç ”ç©¶...'
    };

    for (let i = 0; i < chapters.length; i++) {
      this.checkCancelled();
      const chapter = chapters[i];
      
      yield {
        id: crypto.randomUUID(),
        timestamp: Date.now(),
        type: 'info',
        message: `æ­£åœ¨ç¼–æ’°ç« èŠ‚ ${i+1}/${chapters.length}: ${chapter}`
      };

      // A. Generate Queries
      const { queries, usage: queryTokens } = await this.generateChapterQueries(config.query, chapter, chapterFindingsCache, model);
      totalTokens += queryTokens;
      
      // B. Search
      const chapterFindings: string[] = [];
      const chapterPromptSources = new Set<string>();
      
      for (const q of queries) {
        this.checkCancelled();
        yield { 
            id: crypto.randomUUID(), 
            timestamp: Date.now(), 
            type: 'search', 
            message: `æ£€ç´¢: ${q}`,
            tokenCount: queryTokens
        };
        
        await delay(500); 
        const res = await this.search(q, model);
        const currentQueryIndices: number[] = [];

        // Register sources immediately to bind them to the finding
        if (res.sources && res.sources.length > 0) {
            for (const src of res.sources) {
                let index: number;
                if (uniqueSourceMap.has(src.uri)) {
                    index = uniqueSourceMap.get(src.uri)!;
                } else {
                    globalSources.push(src);
                    index = globalSources.length; // 1-based index
                    uniqueSourceMap.set(src.uri, index);
                }
                currentQueryIndices.push(index);
                chapterPromptSources.add(`[${index}] ${src.title}`);
            }

            yield {
                id: crypto.randomUUID(),
                timestamp: Date.now(),
                type: 'info',
                message: `å‘ç°æº (${res.sources.length})`,
                details: res.sources.map(s => `ğŸ”— ${s.title} - ${s.uri}`)
            };
        }
        
        if (res.summary) {
            // Bind the specific source IDs to this summary block
            // This prevents LLM from citing generic "[ç ”ç©¶ææ–™]"
            const sourceTags = currentQueryIndices.length > 0 
                ? ` (æ¥æºID: ${currentQueryIndices.map(i => `[${i}]`).join(', ')})` 
                : '';
            chapterFindings.push(`èµ„æ–™: "${res.summary}"${sourceTags}`);
        }
      }

      chapterFindingsCache.push(chapterFindings.join('\n').slice(0, 1000)); 

      // D. Write Chapter
      yield { id: crypto.randomUUID(), timestamp: Date.now(), type: 'writing', message: `æ’°å†™: ${chapter}` };
      
      const { content: chapterContent, usage: writeTokens } = await this.writeChapter(
          config.query, 
          chapter, 
          chapterFindings, 
          Array.from(chapterPromptSources), // Pass formatted source list with Global IDs
          model
      );
      totalTokens += writeTokens;
      reportSections.push(chapterContent);

      yield {
        id: crypto.randomUUID(),
        timestamp: Date.now(),
        type: 'info',
        message: `ç« èŠ‚ ${i+1} å®Œæˆ`,
        tokenCount: writeTokens,
        details: { partialSection: chapterContent } 
      };
    }

    // 3. Final Compilation
    const fullReport = `# ${title}\n\n` + reportSections.join('\n\n');
    const wordCount = fullReport.replace(/\s+/g, '').length;

    yield {
      id: crypto.randomUUID(),
      timestamp: Date.now(),
      type: 'info',
      message: "ç ”ç©¶å®Œæˆï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...",
      details: { 
        completedResult: {
          title: title,
          report: fullReport,
          sources: globalSources, // Return strict ordered global list
          totalSearchQueries: this.searchCount,
          totalTokens: totalTokens,
          wordCount: wordCount
        }
      }
    };
  }

  // Helpers
  private async generateChapterQueries(topic: string, chapter: string, prevFindings: string[], model: string): Promise<{ queries: string[], usage: number }> {
    const currentYear = new Date().getFullYear();
    const systemPrompt = "ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¸“å®¶ã€‚è¯·è¿”å›JSONå­—ç¬¦ä¸²æ•°ç»„ã€‚";
    const prompt = `
      ä¸»é¢˜: "${topic}"
      ç« èŠ‚: "${chapter}"
      å½“å‰å¹´ä»½: ${currentYear}
      å‰æ–‡èƒŒæ™¯: ${prevFindings.slice(-3).join('; ')}
      
      ç”Ÿæˆ 3 ä¸ªå…·ä½“ã€é«˜ä»·å€¼çš„æœç´¢æŸ¥è¯¢ã€‚
      **é‡è¦**: ä¼˜å…ˆæŸ¥è¯¢ ${currentYear} å¹´æˆ– ${currentYear-1} å¹´çš„æœ€æ–°æ•°æ®ã€æŠ¥å‘Šå’Œç»Ÿè®¡ã€‚
      
      è¿”å› JSON æ•°ç»„: ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]
    `;
    try {
      const { text, usage } = await this.generateText(prompt, model, systemPrompt, true);
      const cleanText = text.replace(/```json\n|\n```/g, '');
      return { queries: JSON.parse(cleanText), usage: usage || 0 };
    } catch {
      return { queries: [`${topic} ${chapter} ${currentYear} æ•°æ®`, `${topic} ç°çŠ¶`], usage: 0 };
    }
  }

  private async writeChapter(
    topic: string, 
    chapterTitle: string, 
    findings: string[], 
    promptSources: string[], // e.g., ["[1] Source A", "[5] Source B"]
    model: string
  ): Promise<{ content: string, usage: number }> {
    const currentDate = new Date().toLocaleDateString('zh-CN', { year: 'numeric', month: 'long', day: 'numeric' });
    
    const findingsText = findings.join('\n\n');
    const uniquePromptSources = promptSources.join('\n');

    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„æ·±åº¦ç ”ç©¶å‘˜ã€‚å½“å‰æ—¥æœŸæ˜¯ ${currentDate}ã€‚è¯·ç”¨Markdownæ ¼å¼æ’°å†™ã€‚`;
    const prompt = `
      ä¸»é¢˜: "${topic}"
      å½“å‰ç« èŠ‚: "${chapterTitle}"
      
      ç ”ç©¶ææ–™ (Findings) - åŒ…å«å…·ä½“çš„æ¥æºID:
      ${findingsText}
      
      å¯ç”¨å‚è€ƒæ–‡çŒ® (Sources):
      ${uniquePromptSources}
      
      ä»»åŠ¡: æ’°å†™æœ¬ç« èŠ‚å†…å®¹ã€‚
      
      è¦æ±‚:
      1. **æ•°æ®æ—¶æ•ˆæ€§**: åŠ¡å¿…ä»¥ ${currentDate} çš„è§†è§’è¿›è¡Œå†™ä½œã€‚
      2. **å­¦æœ¯è¯­è°ƒ**: æ­£å¼ã€å®¢è§‚ã€æ·±åº¦ã€‚ç®€ä½“ä¸­æ–‡ã€‚
      3. **ç¯‡å¹…**: è¯¦å°½ï¼ˆçº¦ 800-1500 å­—ï¼‰ã€‚
      4. **å¼•ç”¨è§„èŒƒ (å…³é”®)**: 
         - ç ”ç©¶ææ–™ä¸­å·²æ ‡è®°äº†æ¥æºID (å¦‚ "æ¥æºID: [1], [2]")ã€‚
         - **å¿…é¡»**åœ¨æ–‡ä¸­å¼•ç”¨äº‹å®ã€æ•°æ®æˆ–è§‚ç‚¹æ—¶ï¼Œåœ¨å¥å°¾ä½¿ç”¨ä¸Šæ ‡æ•°å­— **[x]** æ ‡æ³¨æ¥æºã€‚
         - **ä¸¥ç¦**ä½¿ç”¨ "[ç ”ç©¶ææ–™]"ã€"[èµ„æ–™]"ã€"[Source]" æˆ–å…¶ä»–éæ•°å­—å¼•ç”¨ã€‚
         - **ä¸¥ç¦**ç¼–é€ æœªå‡ºç°åœ¨ "å¯ç”¨å‚è€ƒæ–‡çŒ®" ä¸­çš„ç¼–å·ã€‚
         - ä¾‹å¦‚: "æ ¹æ®æœ€æ–°æŠ¥å‘Šæ˜¾ç¤ºï¼Œå¢é•¿ç‡ä¸º5% [1]ã€‚"
      5. **ç²—ä½“ä¸å¼•å·è§„èŒƒ**:
         - **ä¸¥ç¦**ä½¿ç”¨ **"æ–‡æœ¬"** æˆ– **â€œæ–‡æœ¬â€** çš„æ ¼å¼ã€‚
         - **å¿…é¡»**å°†å¼•å·æ”¾åœ¨ç²—ä½“æ ‡è®°ä¹‹å¤–ã€‚
         - æ­£ç¡®ç¤ºä¾‹: "**æ ¸å¿ƒæ¦‚å¿µ**" æˆ– "æ ¹æ® **æŠ¥å‘Š** æŒ‡å‡º"ã€‚
      6. **å¯è§†åŒ–**: å¿…é¡»åŒ…å«ä¸€ä¸ª Mermaid.js å›¾è¡¨ã€‚
         - **Mermaid è§„èŒƒ**: 
           - ä¼˜å…ˆä½¿ç”¨ \`graph TD\` (æµç¨‹å›¾), \`pie\` (é¥¼å›¾), \`sequenceDiagram\` (æ—¶åºå›¾) ç­‰ç¨³å®šè¯­æ³•ã€‚
           - **æ…ç”¨ \`quadrantChart\`**: ä»…åœ¨å®Œå…¨ç¡®å®šè¯­æ³•æ­£ç¡®ï¼ˆéœ€å®šä¹‰å››ä¸ª quadrant æ ‡ç­¾å’Œ x-axis/y-axis èŒƒå›´ï¼‰æ—¶ä½¿ç”¨ã€‚è‹¥ä¸ç¡®å®šï¼Œè¯·æ”¹ç”¨æ™®é€šå›¾è¡¨ï¼Œä»¥å…æ¸²æŸ“é”™è¯¯ã€‚
           - ä»…ä½¿ç”¨è‹±æ–‡ID (NodeA)ï¼Œä¸¥ç¦åœ¨å›¾è¡¨ä»£ç ä¸­æåŠ "mermaid" å­—çœ¼ï¼Œä»…ç”¨ "ä¸‹å›¾å±•ç¤º..." å¼•å‡ºã€‚
           - èŠ‚ç‚¹æ–‡æœ¬ç”¨è‹±æ–‡åŒå¼•å·ã€‚
      7. **çº¯å‡€æ–‡æœ¬**: é™¤å»å¼•ç”¨æ ‡è®° [x] å¤–ï¼Œä¸è¦æ·»åŠ å…¶ä»–å…ƒæ•°æ®æ ‡è®°ã€‚
      
      ç›´æ¥è¾“å‡º Markdown å†…å®¹ã€‚
    `;

    const result = await this.generateText(prompt, model, systemPrompt);
    return { content: result.text, usage: result.usage || 0 };
  }
}