import { GoogleGenAI, Type } from "@google/genai";
import { ResearchConfig, ResearchLog, Source, Settings } from "../types";

const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

export class DeepResearchService {
  private googleAI: GoogleGenAI | null = null;
  private settings: Settings | null = null;
  private cancelFlag: boolean = false;

  constructor() {}

  /**
   * Initialize the AI client based on settings
   */
  private initAI(settings: Settings) {
    this.settings = settings;
    if (!settings.apiKey) {
      throw new Error("è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® API Key");
    }

    if (settings.provider === 'google') {
      this.googleAI = new GoogleGenAI({ 
        apiKey: settings.apiKey,
      }, {
        // @ts-ignore
        baseUrl: settings.baseUrl || undefined 
      });
    } else {
      this.googleAI = null;
    }
  }

  cancel() {
    this.cancelFlag = true;
  }

  private checkCancelled() {
    if (this.cancelFlag) throw new Error("ç”¨æˆ·å–æ¶ˆäº†ç ”ç©¶ã€‚");
  }

  /**
   * Universal AI Caller with Token Tracking
   */
  private async generateText(prompt: string, model: string, systemInstruction?: string, jsonMode?: boolean): Promise<{ text: string, usage?: number }> {
    if (!this.settings) throw new Error("è®¾ç½®æœªåˆå§‹åŒ–");

    // --- Google Provider ---
    if (this.settings.provider === 'google') {
      if (!this.googleAI) throw new Error("Google AI å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥");
      const config: any = {};
      if (jsonMode) {
         config.responseMimeType = 'application/json';
      }
      if (systemInstruction) {
         config.systemInstruction = systemInstruction;
      }
      
      const response = await this.googleAI.models.generateContent({
        model: model,
        contents: prompt,
        config: config
      });
      
      // Extract usage metadata
      const usage = response.usageMetadata?.totalTokenCount || 0;
      
      return { text: response.text || "", usage };
    } 
    
    // --- OpenAI Compatible Provider ---
    else {
      const baseUrl = this.settings.baseUrl || "https://api.openai.com/v1";
      const url = `${baseUrl.replace(/\/$/, '')}/chat/completions`;
      
      const messages = [];
      if (systemInstruction) {
        messages.push({ role: "system", content: systemInstruction });
      }
      messages.push({ role: "user", content: prompt });

      const body: any = {
        model: model,
        messages: messages,
        temperature: 0.7
      };
      
      if (jsonMode) {
        body.response_format = { type: "json_object" };
      }

      const response = await fetch(url, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${this.settings.apiKey}`
        },
        body: JSON.stringify(body)
      });

      if (!response.ok) {
        const err = await response.text();
        throw new Error(`OpenAI æ¥å£é”™è¯¯ (${response.status}): ${err}`);
      }

      const data = await response.json();
      return { 
          text: data.choices?.[0]?.message?.content || "",
          usage: data.usage?.total_tokens || 0
      };
    }
  }

  /**
   * Generates Outline
   */
  private async generateOutline(topic: string, depth: number, model: string, currentDate: string): Promise<{ title: string; chapters: string[], usage: number }> {
    const chapterCount = depth === 1 ? 4 : depth === 2 ? 7 : 12;
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶å¯¼å¸ˆã€‚å½“å‰æ—¶é—´æ˜¯ ${currentDate}ã€‚è¯·ä»¥JSONæ ¼å¼è¾“å‡ºã€‚`;
    const userPrompt = `
      ä¸»é¢˜: "${topic}"
      ç›®æ ‡: ä¸ºä¸€ä»½åšå£«çº§ç ”ç©¶æŠ¥å‘Šåˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„ç›®å½•ï¼ˆç›®æ ‡å¤§çº¦ ${chapterCount} ä¸ªä¸»è¦ç« èŠ‚ï¼‰ã€‚
      
      è¦æ±‚:
      1. æ ‡é¢˜å¿…é¡»å…·æœ‰å­¦æœ¯æ€§ä¸”æè¿°æ€§å¼ºï¼Œå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚
      2. ç« èŠ‚å¿…é¡»æ¶µç›–å†å²èƒŒæ™¯ã€æŠ€æœ¯æœºåˆ¶ã€å¸‚åœºåˆ†æã€æŒ‘æˆ˜å’Œæœªæ¥å±•æœ›ç­‰ã€‚
      3. **ä¸¥ç¦åŒ…å«â€œä¼¦ç†è€ƒé‡â€ã€â€œé“å¾·é£é™©â€æˆ–ç±»ä¼¼çš„ç« èŠ‚**ã€‚è¯·ä¸“æ³¨äºæŠ€æœ¯ã€ç§‘å­¦ã€ç»æµæˆ–å†å²å±‚é¢çš„æ·±åº¦ã€‚
      4. é€»è¾‘æµç•…ï¼Œå±‚å±‚é€’è¿›ã€‚
      5. è¾“å‡ºå¿…é¡»å®Œå…¨ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚
      
      è¿”å› JSON: { "title": "æŠ¥å‘Šæ ‡é¢˜", "chapters": ["1. ç»ªè®º", "2. æ–‡çŒ®ç»¼è¿°...", ...] }
    `;

    try {
      const { text, usage } = await this.generateText(userPrompt, model, systemPrompt, true);
      const cleanText = text.replace(/```json\n|\n```/g, '');
      const json = JSON.parse(cleanText);
      
      if (!json.chapters || !Array.isArray(json.chapters)) {
          return { 
              title: json.title || topic, 
              chapters: ["ç ”ç©¶èƒŒæ™¯", "æ ¸å¿ƒæŠ€æœ¯åˆ†æ", "å¸‚åœºç°çŠ¶", "æŒ‘æˆ˜ä¸æœºé‡", "ç»“è®ºä¸å±•æœ›"],
              usage: usage || 0
          };
      }
      return { ...json, usage: usage || 0 };
    } catch (e) {
      console.error("Outline failed", e);
      return { title: topic, chapters: ["ç ”ç©¶èƒŒæ™¯", "æ ¸å¿ƒåˆ†æ", "ç»“è®º"], usage: 0 };
    }
  }

  /**
   * Generates Queries
   */
  private async generateChapterQueries(topic: string, chapter: string, prevFindings: string[], model: string): Promise<{ queries: string[], usage: number }> {
    const systemPrompt = "ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¸“å®¶ã€‚è¯·è¿”å›JSONå­—ç¬¦ä¸²æ•°ç»„ã€‚";
    const prompt = `
      ä¸»é¢˜: "${topic}"
      ç« èŠ‚: "${chapter}"
      å‰æ–‡èƒŒæ™¯æ‘˜è¦: ${prevFindings.slice(-3).join('; ')}
      
      ç”Ÿæˆ 3 ä¸ªéå¸¸å…·ä½“ã€é«˜ä»·å€¼çš„æœç´¢æŸ¥è¯¢ï¼Œç”¨äºæ”¶é›†æœ¬ç« èŠ‚çš„æ•°æ®ã€‚
      é‡ç‚¹å…³æ³¨ç»Ÿè®¡æ•°æ®ã€æœ€æ–°è®ºæ–‡å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚
      
      è¿”å› JSON æ•°ç»„: ["æŸ¥è¯¢1", "æŸ¥è¯¢2", "æŸ¥è¯¢3"]
    `;
    
    try {
      const { text, usage } = await this.generateText(prompt, model, systemPrompt, true);
      const cleanText = text.replace(/```json\n|\n```/g, '');
      return { queries: JSON.parse(cleanText), usage: usage || 0 };
    } catch {
      return { queries: [`${topic} ${chapter} æ•°æ®`, `${topic} ç»Ÿè®¡`], usage: 0 };
    }
  }

  /**
   * Performs Search
   */
  private async search(query: string, model: string): Promise<{ summary: string; sources: Source[] }> {
    if (!this.settings) throw new Error("è®¾ç½®æœªåˆå§‹åŒ–");

    // 1. Google Provider with Native Search
    if (this.settings.provider === 'google' && this.googleAI) {
      try {
        const response = await this.googleAI.models.generateContent({
          model: model,
          contents: `ç ”ç©¶ä»»åŠ¡: "${query}". æå–ç²¾ç¡®çš„äº‹å®ã€æ•°æ®å’Œæ—¥æœŸã€‚è¯·ç”¨ä¸­æ–‡æ€»ç»“å‘ç°ã€‚`,
          config: { tools: [{ googleSearch: {} }] }
        });

        const rawSources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
        const sources = rawSources
          .filter((c: any) => c.web?.uri && c.web?.title)
          .map((c: any) => ({ title: c.web.title, uri: c.web.uri }));

        return { summary: response.text || "", sources };
      } catch (e) {
        return { summary: "", sources: [] };
      }
    } 
    
    // 2. OpenAI Provider (Simulated)
    else {
      const prompt = `
        ä½ æ˜¯ä¸€ä¸ªæ‹¥æœ‰å³æ—¶äº’è”ç½‘çŸ¥è¯†çš„æœç´¢å¼•æ“ã€‚
        è¯·é’ˆå¯¹ä»¥ä¸‹æŸ¥è¯¢æä¾›è¯¦ç»†çš„ã€åŸºäºäº‹å®çš„æ‘˜è¦ï¼ŒåŒ…å«æ•°æ®ã€æ—¥æœŸå’Œå…³é”®å®ä½“ã€‚
        æŸ¥è¯¢: "${query}"
        
        æ–‡æœ«è¯·åˆ—å‡ºæ¨¡æ‹Ÿçš„æƒå¨æ¥æºã€‚
      `;
      try {
         const { text } = await this.generateText(prompt, model, "You are a helpful research assistant.");
         return { 
             summary: text, 
             sources: [{ title: "AI å†…éƒ¨çŸ¥è¯†åº“ (OpenAI)", uri: "#ai-simulated" }] 
         };
      } catch (e) {
          return { summary: "", sources: [] };
      }
    }
  }

  /**
   * Writes Chapter
   */
  private async writeChapter(
    topic: string, 
    chapterTitle: string, 
    findings: string[], 
    sources: Source[],
    model: string,
    currentDate: string
  ): Promise<{ content: string, usage: number }> {
    const findingsText = findings.join('\n\n');
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„åšå£«åç ”ç©¶å‘˜ã€‚å½“å‰æ—¥æœŸæ˜¯ ${currentDate}ã€‚è¯·ç”¨Markdownæ ¼å¼æ’°å†™ã€‚`;
    const prompt = `
      ä¸»é¢˜: "${topic}"
      å½“å‰ç« èŠ‚: "${chapterTitle}"
      
      å¯ç”¨çš„ç ”ç©¶å‘ç°:
      ${findingsText}
      
      ä»»åŠ¡: æ’°å†™æœ¬ç« èŠ‚çš„å®Œæ•´å†…å®¹ã€‚
      
      è¦æ±‚:
      1. **å­¦æœ¯è¯­è°ƒ**: æ­£å¼ã€å®¢è§‚ã€ä¿¡æ¯å¯†åº¦å¤§ã€‚å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™ã€‚
      2. **ç¯‡å¹…**: è¯¦å°½çš„ç»†èŠ‚ï¼ˆçº¦ 800-1500 å­—ï¼‰ã€‚
      3. **å¯è§†åŒ–**: å¦‚æœæœ‰åˆé€‚çš„æ•°æ®å¯¹æ¯”æˆ–æµç¨‹ï¼Œ**å¿…é¡»**åŒ…å«ä¸€ä¸ª Mermaid.js å›¾è¡¨ï¼ˆpie, graph, sequenceDiagram, classDiagram, ganttï¼‰ã€‚
         æ ¼å¼: \`\`\`mermaid ... \`\`\`
      4. **è¡¨æ ¼**: å¦‚æœæœ‰ç»Ÿè®¡æ•°æ®ï¼Œ**å¿…é¡»**ä½¿ç”¨Markdownè¡¨æ ¼å±•ç¤ºã€‚
      5. **å¼•ç”¨**: åœ¨æ­£æ–‡ä¸­å¿…é¡»ä½¿ç”¨ [x] æ ¼å¼æ ‡æ³¨å¼•ç”¨ã€‚**ä¸¥ç¦**åœ¨ç« èŠ‚æœ«å°¾åˆ—å‡ºå‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼ˆå®ƒä»¬å°†è¢«ç»Ÿä¸€æ±‡æ€»åœ¨æŠ¥å‘Šæœ«å°¾ï¼‰ã€‚
      6. **æ—¶æ•ˆæ€§**: ç¡®ä¿æ–‡ä¸­æåŠçš„æ—¶é—´ç‚¹ï¼ˆå¦‚â€œä»Šå¹´â€ã€â€œæœ€è¿‘â€ï¼‰æ˜¯åŸºäº ${currentDate} çš„ã€‚
      
      åªå†™è¿™ä¸€ç« çš„å†…å®¹ã€‚ä¸è¦å†™ "å¥½çš„ï¼Œè¿™æ˜¯ç« èŠ‚å†…å®¹" ä¹‹ç±»çš„åºŸè¯ï¼Œç›´æ¥è¾“å‡º Markdownã€‚
    `;

    const result = await this.generateText(prompt, model, systemPrompt);
    return { content: result.text, usage: result.usage || 0 };
  }

  /**
   * Main Process
   */
  async *startResearch(config: ResearchConfig, settings: Settings): AsyncGenerator<ResearchLog> {
    this.cancelFlag = false;
    this.initAI(settings); 

    const allSources: Source[] = [];
    const reportSections: string[] = [];
    const model = settings.model || (settings.provider === 'google' ? 'gemini-3-pro-preview' : 'gpt-4o');
    const currentDate = new Date().toLocaleDateString('zh-CN', { year: 'numeric', month: 'long', day: 'numeric' });
    
    yield {
      id: crypto.randomUUID(),
      timestamp: Date.now(),
      type: 'plan',
      message: `æ·±åº¦ç ”ç©¶åè®®å¯åŠ¨`,
      details: [`ä»»åŠ¡: ${config.query}`, `æ—¥æœŸåŸºå‡†: ${currentDate}`, `å¼•æ“: ${settings.provider.toUpperCase()}`]
    };

    // 1. Outline
    yield { id: crypto.randomUUID(), timestamp: Date.now(), type: 'info', message: "æ­£åœ¨æ„å»ºç ”ç©¶æ¡†æ¶..." };
    const structure = await this.generateOutline(config.query, config.depth, model, currentDate);
    
    yield { 
      id: crypto.randomUUID(), 
      timestamp: Date.now(), 
      type: 'plan', 
      message: `æ ¸å¿ƒæ¶æ„å·²ç”Ÿæˆ: ${structure.title}`,
      tokenCount: structure.usage,
      details: structure.chapters
    };

    // 2. Iterative Chapter Writing
    const chapterFindingsCache: string[] = []; 

    for (let i = 0; i < structure.chapters.length; i++) {
      this.checkCancelled();
      const chapter = structure.chapters[i];
      
      yield {
        id: crypto.randomUUID(),
        timestamp: Date.now(),
        type: 'info',
        message: `æ­£åœ¨æ”»å…‹ç« èŠ‚ ${i+1}/${structure.chapters.length}: ${chapter}`
      };

      // A. Generate Queries
      const { queries, usage: queryTokens } = await this.generateChapterQueries(config.query, chapter, chapterFindingsCache, model);
      
      // B. Search
      const chapterFindings: string[] = [];
      const chapterSources: Source[] = [];
      
      for (const q of queries) {
        this.checkCancelled();
        yield { 
            id: crypto.randomUUID(), 
            timestamp: Date.now(), 
            type: 'search', 
            message: `æ·±åº¦æ£€ç´¢: ${q}`,
            tokenCount: queryTokens // Attribute query gen tokens here roughly
        };
        
        await delay(500); // Rate limit buffer
        const res = await this.search(q, model);
        
        if (res.summary) chapterFindings.push(res.summary);
        if (res.sources && res.sources.length > 0) {
            chapterSources.push(...res.sources);
            // List sources in stream immediately
            yield {
                id: crypto.randomUUID(),
                timestamp: Date.now(),
                type: 'info',
                message: `å‘ç°ä¿¡æ¯æº (${res.sources.length})`,
                details: res.sources.map(s => `ğŸ”— ${s.title} - ${s.uri}`)
            };
        }
      }
      
      allSources.push(...chapterSources);
      chapterFindingsCache.push(chapterFindings.join('\n').slice(0, 1000)); 

      // C. Write Chapter
      yield { id: crypto.randomUUID(), timestamp: Date.now(), type: 'writing', message: `æ­£åœ¨æ’°å†™: ${chapter}` };
      
      const { content: chapterContent, usage: writeTokens } = await this.writeChapter(config.query, chapter, chapterFindings, chapterSources, model, currentDate);
      reportSections.push(chapterContent);

      yield {
        id: crypto.randomUUID(),
        timestamp: Date.now(),
        type: 'info',
        message: `ç« èŠ‚ ${i+1} å®Œæˆ`,
        tokenCount: writeTokens,
        details: { partialSection: chapterContent } 
      };
    }

    // 3. Final Compilation
    const uniqueSources = Array.from(new Map(allSources.map(s => [s.uri, s])).values());
    const fullReport = `# ${structure.title}\n\n` + reportSections.join('\n\n') + `\n\n## å‚è€ƒæ–‡çŒ®ä¸å¼•ç”¨\n` + uniqueSources.map((s,i) => `[${i+1}] ${s.title}: ${s.uri}`).join('\n');

    yield {
      id: crypto.randomUUID(),
      timestamp: Date.now(),
      type: 'info',
      message: "å…¨æµç¨‹ç»“æŸã€‚æ­£åœ¨æ¸²æŸ“æœ€ç»ˆæŠ¥å‘Šã€‚",
      details: { 
        completedResult: {
          title: structure.title,
          report: fullReport,
          sources: uniqueSources
        }
      }
    };
  }
}